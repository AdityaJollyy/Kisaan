#!/usr/bin/env python3
"""
AI Training Dataset Generator for Kisaan Agricultural Platform
Generates comprehensive training data for farmer inventory management in multiple Indian languages.

This script creates a JSONL dataset covering:
- Inventory actions: check, update, increase, decrease, remove, add
- Multiple languages: English, Hindi, Bengali, Telugu, Marathi, Tamil, Gujarati, etc.
- Quantities up to 1000kg with various units
- Natural conversation patterns farmers might use
- Different product categories and scenarios
"""

import json
import os
import random
import itertools
from typing import Dict, List, Tuple, Any
from datetime import datetime

class FarmerInventoryDatasetGenerator:
    def __init__(self):
        self.languages = {
            'en': 'English',
            'hi': 'Hindi', 
            'bn': 'Bengali',
            'te': 'Telugu',
            'mr': 'Marathi',
            'ta': 'Tamil',
            'gu': 'Gujarati',
            'kn': 'Kannada',
            'ml': 'Malayalam',
            'pa': 'Punjabi',
            'or': 'Odia',
            'as': 'Assamese',
            'ur': 'Urdu'
        }
        
        # Common Indian crops and products
        self.products = {
            'en': {
                'grains': ['rice', 'wheat', 'barley', 'maize', 'bajra', 'jowar'],
                'vegetables': ['tomato', 'onion', 'potato', 'brinjal', 'okra', 'spinach', 'cabbage', 'cauliflower', 'peas', 'beans'],
                'fruits': ['mango', 'banana', 'apple', 'orange', 'grapes', 'guava', 'papaya', 'pomegranate'],
                'pulses': ['moong', 'masoor', 'chana', 'toor', 'urad', 'rajma'],
                'spices': ['turmeric', 'coriander', 'cumin', 'red chili', 'cardamom', 'black pepper']
            },
            'hi': {
                'grains': ['à¤šà¤¾à¤µà¤²', 'à¤—à¥‡à¤¹à¥‚à¤‚', 'à¤œà¥Œ', 'à¤®à¤•à¥à¤•à¤¾', 'à¤¬à¤¾à¤œà¤°à¤¾', 'à¤œà¥à¤µà¤¾à¤°'],
                'vegetables': ['à¤Ÿà¤®à¤¾à¤Ÿà¤°', 'à¤ªà¥à¤¯à¤¾à¤œ', 'à¤†à¤²à¥‚', 'à¤¬à¥ˆà¤‚à¤—à¤¨', 'à¤­à¤¿à¤‚à¤¡à¥€', 'à¤ªà¤¾à¤²à¤•', 'à¤ªà¤¤à¥à¤¤à¤¾à¤—à¥‹à¤­à¥€', 'à¤«à¥‚à¤²à¤—à¥‹à¤­à¥€', 'à¤®à¤Ÿà¤°', 'à¤¬à¥€à¤¨à¥à¤¸'],
                'fruits': ['à¤†à¤®', 'à¤•à¥‡à¤²à¤¾', 'à¤¸à¥‡à¤¬', 'à¤¸à¤‚à¤¤à¤°à¤¾', 'à¤…à¤‚à¤—à¥‚à¤°', 'à¤…à¤®à¤°à¥‚à¤¦', 'à¤ªà¤ªà¥€à¤¤à¤¾', 'à¤…à¤¨à¤¾à¤°'],
                'pulses': ['à¤®à¥‚à¤‚à¤—', 'à¤®à¤¸à¥‚à¤°', 'à¤šà¤¨à¤¾', 'à¤¤à¥‚à¤°', 'à¤‰à¤¡à¤¼à¤¦', 'à¤°à¤¾à¤œà¤®à¤¾'],
                'spices': ['à¤¹à¤²à¥à¤¦à¥€', 'à¤§à¤¨à¤¿à¤¯à¤¾', 'à¤œà¥€à¤°à¤¾', 'à¤²à¤¾à¤² à¤®à¤¿à¤°à¥à¤š', 'à¤‡à¤²à¤¾à¤¯à¤šà¥€', 'à¤•à¤¾à¤²à¥€ à¤®à¤¿à¤°à¥à¤š']
            },
            'bn': {
                'grains': ['à¦§à¦¾à¦¨', 'à¦—à¦®', 'à¦¯à¦¬', 'à¦­à§à¦Ÿà§à¦Ÿà¦¾', 'à¦¬à¦¾à¦œà¦°à¦¾', 'à¦œà§‹à¦¯à¦¼à¦¾à¦°'],
                'vegetables': ['à¦Ÿà¦®à§‡à¦Ÿà§‹', 'à¦ªà§‡à¦à¦¯à¦¼à¦¾à¦œ', 'à¦†à¦²à§', 'à¦¬à§‡à¦—à§à¦¨', 'à¦¢à§‡à¦à¦¡à¦¼à¦¸', 'à¦ªà¦¾à¦²à¦‚ à¦¶à¦¾à¦•', 'à¦¬à¦¾à¦à¦§à¦¾à¦•à¦ªà¦¿', 'à¦«à§à¦²à¦•à¦ªà¦¿', 'à¦®à¦Ÿà¦°', 'à¦¬à¦¿à¦¨'],
                'fruits': ['à¦†à¦®', 'à¦•à¦²à¦¾', 'à¦†à¦ªà§‡à¦²', 'à¦•à¦®à¦²à¦¾', 'à¦†à¦™à§à¦°', 'à¦ªà§‡à¦¯à¦¼à¦¾à¦°à¦¾', 'à¦ªà§‡à¦à¦ªà§‡', 'à¦¡à¦¾à¦²à¦¿à¦®'],
                'pulses': ['à¦®à§à¦—', 'à¦®à¦¸à§à¦°', 'à¦›à§‹à¦²à¦¾', 'à¦¤à§à¦°', 'à¦‰à¦¡à¦¼à¦¦', 'à¦°à¦¾à¦œà¦®à¦¾'],
                'spices': ['à¦¹à¦²à§à¦¦', 'à¦§à¦¨à§‡', 'à¦œà¦¿à¦°à¦¾', 'à¦²à¦¾à¦² à¦®à¦°à¦¿à¦š', 'à¦à¦²à¦¾à¦š', 'à¦•à¦¾à¦²à§‹ à¦®à¦°à¦¿à¦š']
            }
        }
        
        # Add more language translations for key products
        self.add_more_language_translations()
        
        self.units = {
            'en': ['kg', 'grams', 'tonnes', 'quintals', 'bags', 'boxes', 'pieces'],
            'hi': ['à¤•à¤¿à¤²à¥‹', 'à¤—à¥à¤°à¤¾à¤®', 'à¤Ÿà¤¨', 'à¤•à¥à¤µà¤¿à¤‚à¤Ÿà¤²', 'à¤¬à¥‹à¤°à¥€', 'à¤¬à¤•à¥à¤¸à¥‡', 'à¤ªà¥€à¤¸'],
            'bn': ['à¦•à§‡à¦œà¦¿', 'à¦—à§à¦°à¦¾à¦®', 'à¦Ÿà¦¨', 'à¦•à§à¦‡à¦¨à§à¦Ÿà¦¾à¦²', 'à¦¬à¦¸à§à¦¤à¦¾', 'à¦¬à¦¾à¦•à§à¦¸', 'à¦ªà¦¿à¦¸']
        }
        
        self.actions = {
            'en': {
                'check': ['check', 'show', 'tell me', 'what is', 'how much', 'what\'s the stock'],
                'update': ['update', 'set', 'change', 'modify', 'make it'],
                'increase': ['add', 'increase', 'more', 'plus', 'additional'],
                'decrease': ['reduce', 'decrease', 'less', 'minus', 'remove some'],
                'remove': ['remove', 'delete', 'clear', 'take out'],
                'add_new': ['add new', 'create', 'register', 'include']
            },
            'hi': {
                'check': ['à¤šà¥‡à¤• à¤•à¤°à¥‡à¤‚', 'à¤¦à¥‡à¤–à¥‡à¤‚', 'à¤¬à¤¤à¤¾à¤à¤‚', 'à¤•à¥à¤¯à¤¾ à¤¹à¥ˆ', 'à¤•à¤¿à¤¤à¤¨à¤¾ à¤¹à¥ˆ', 'à¤¸à¥à¤Ÿà¥‰à¤• à¤•à¤¿à¤¤à¤¨à¤¾ à¤¹à¥ˆ'],
                'update': ['à¤…à¤ªà¤¡à¥‡à¤Ÿ à¤•à¤°à¥‡à¤‚', 'à¤¸à¥‡à¤Ÿ à¤•à¤°à¥‡à¤‚', 'à¤¬à¤¦à¤²à¥‡à¤‚', 'à¤¸à¤‚à¤¶à¥‹à¤§à¤¿à¤¤ à¤•à¤°à¥‡à¤‚', 'à¤¬à¤¨à¤¾ à¤¦à¥‡à¤‚'],
                'increase': ['à¤œà¥‹à¤¡à¤¼à¥‡à¤‚', 'à¤¬à¤¢à¤¼à¤¾à¤à¤‚', 'à¤”à¤°', 'à¤ªà¥à¤²à¤¸', 'à¤…à¤¤à¤¿à¤°à¤¿à¤•à¥à¤¤'],
                'decrease': ['à¤•à¤® à¤•à¤°à¥‡à¤‚', 'à¤˜à¤Ÿà¤¾à¤à¤‚', 'à¤•à¤®', 'à¤®à¤¾à¤‡à¤¨à¤¸', 'à¤•à¥à¤› à¤¹à¤Ÿà¤¾à¤à¤‚'],
                'remove': ['à¤¹à¤Ÿà¤¾à¤à¤‚', 'à¤®à¤¿à¤Ÿà¤¾à¤à¤‚', 'à¤¸à¤¾à¤« à¤•à¤°à¥‡à¤‚', 'à¤¨à¤¿à¤•à¤¾à¤²à¥‡à¤‚'],
                'add_new': ['à¤¨à¤¯à¤¾ à¤œà¥‹à¤¡à¤¼à¥‡à¤‚', 'à¤¬à¤¨à¤¾à¤à¤‚', 'à¤°à¤œà¤¿à¤¸à¥à¤Ÿà¤° à¤•à¤°à¥‡à¤‚', 'à¤¶à¤¾à¤®à¤¿à¤² à¤•à¤°à¥‡à¤‚']
            },
            'bn': {
                'check': ['à¦šà§‡à¦• à¦•à¦°à§à¦¨', 'à¦¦à§‡à¦–à§à¦¨', 'à¦¬à¦²à§à¦¨', 'à¦•à¦¿ à¦†à¦›à§‡', 'à¦•à¦¤ à¦†à¦›à§‡', 'à¦¸à§à¦Ÿà¦• à¦•à¦¤'],
                'update': ['à¦†à¦ªà¦¡à§‡à¦Ÿ à¦•à¦°à§à¦¨', 'à¦¸à§‡à¦Ÿ à¦•à¦°à§à¦¨', 'à¦ªà¦°à¦¿à¦¬à¦°à§à¦¤à¦¨ à¦•à¦°à§à¦¨', 'à¦¸à¦‚à¦¶à§‹à¦§à¦¨ à¦•à¦°à§à¦¨', 'à¦•à¦°à§à¦¨'],
                'increase': ['à¦¯à§‹à¦— à¦•à¦°à§à¦¨', 'à¦¬à¦¾à¦¡à¦¼à¦¾à¦¨', 'à¦†à¦°à§‹', 'à¦ªà§à¦²à¦¾à¦¸', 'à¦…à¦¤à¦¿à¦°à¦¿à¦•à§à¦¤'],
                'decrease': ['à¦•à¦®à¦¾à¦¨', 'à¦¹à§à¦°à¦¾à¦¸ à¦•à¦°à§à¦¨', 'à¦•à¦®', 'à¦®à¦¾à¦‡à¦¨à¦¾à¦¸', 'à¦•à¦¿à¦›à§ à¦¸à¦°à¦¾à¦¨'],
                'remove': ['à¦¸à¦°à¦¾à¦¨', 'à¦®à§à¦›à§à¦¨', 'à¦ªà¦°à¦¿à¦·à§à¦•à¦¾à¦° à¦•à¦°à§à¦¨', 'à¦¬à§‡à¦° à¦•à¦°à§à¦¨'],
                'add_new': ['à¦¨à¦¤à§à¦¨ à¦¯à§‹à¦— à¦•à¦°à§à¦¨', 'à¦¤à§ˆà¦°à¦¿ à¦•à¦°à§à¦¨', 'à¦¨à¦¿à¦¬à¦¨à§à¦§à¦¨ à¦•à¦°à§à¦¨', 'à¦…à¦¨à§à¦¤à¦°à§à¦­à§à¦•à§à¦¤ à¦•à¦°à§à¦¨']
            }
        }
        
        # Add units and actions for more languages
        self.add_more_language_units_actions()
        
        self.conversation_patterns = {
            'check': [
                "How much {product} do I have?",
                "Check my {product} stock",
                "What's the current inventory of {product}?",
                "Show me {product} quantity",
                "Tell me about {product} stock level"
            ],
            'update': [
                "Update {product} to {quantity} {unit}",
                "Set {product} stock to {quantity} {unit}",
                "Change {product} quantity to {quantity} {unit}",
                "Make {product} {quantity} {unit}",
                "Modify {product} stock to {quantity} {unit}"
            ],
            'increase': [
                "Add {quantity} {unit} of {product}",
                "Increase {product} by {quantity} {unit}",
                "I got {quantity} {unit} more {product}",
                "Plus {quantity} {unit} {product}",
                "Additional {quantity} {unit} of {product}"
            ],
            'decrease': [
                "Remove {quantity} {unit} of {product}",
                "Decrease {product} by {quantity} {unit}",
                "Sold {quantity} {unit} of {product}",
                "Minus {quantity} {unit} {product}",
                "Reduce {product} by {quantity} {unit}"
            ],
            'remove': [
                "Remove all {product}",
                "Delete {product} from inventory",
                "Clear {product} stock",
                "Take out all {product}",
                "Remove {product} completely"
            ],
            'add_new': [
                "Add new {product} to inventory",
                "Register {product} as new product",
                "Include {product} in my stock",
                "Create new entry for {product}",
                "Add {product} to my product list"
            ]
        }
        
        # Add translated patterns for other languages
        self.add_translated_patterns()
        
    def add_more_language_translations(self):
        """Add product translations for more languages"""
        # Telugu
        self.products['te'] = {
            'grains': ['à°µà°°à°¿', 'à°—à±‹à°§à±à°®', 'à°¯à°µà°²à±', 'à°®à±Šà°•à±à°•à°œà±Šà°¨à±à°¨', 'à°¸à°œà±à°œà°²à±', 'à°œà±Šà°¨à±à°¨'],
            'vegetables': ['à°Ÿà°®à°¾à°Ÿà±‹', 'à°‰à°²à±à°²à°¿à°ªà°¾à°¯', 'à°¬à°‚à°—à°¾à°³à°¾à°¦à±à°‚à°ª', 'à°µà°‚à°•à°¾à°¯', 'à°¬à±†à°‚à°¡à°•à°¾à°¯', 'à°ªà°¾à°²à°•à±‚à°°', 'à°•à°¾à°¬à±‡à°œà±€', 'à°•à°¾à°²à±€à°«à±à°²à°µà°°à±', 'à°¬à° à°¾à°¨à±€à°²à±', 'à°¬à±€à°¨à±à°¸à±'],
            'fruits': ['à°®à°¾à°®à°¿à°¡à°¿', 'à°…à°°à°Ÿà°¿', 'à°†à°ªà°¿à°²à±', 'à°¨à°¾à°°à°¿à°‚à°œ', 'à°¦à±à°°à°¾à°•à±à°·', 'à°œà°¾à°®', 'à°¬à±Šà°ªà±à°ªà°¾à°¯à°¿', 'à°¦à°¾à°¨à°¿à°®à±à°®'],
            'pulses': ['à°ªà±†à°¸à°²à±', 'à°®à°¸à±‚à°°à±', 'à°¶à°¨à°—à°²à±', 'à°•à°‚à°¦à°¿', 'à°®à°¿à°¨à±à°®à±à°²à±', 'à°°à°¾à°œà±à°®à°¾'],
            'spices': ['à°ªà°¸à±à°ªà±', 'à°§à°¨à°¿à°¯à°¾à°²à±', 'à°œà±€à°²à°•à°°à±à°°', 'à°Žà°°à±à°°à°®à°¿à°°à±à°šà°¿', 'à°à°²à°•à±à°²à±', 'à°¨à°²à±à°²à°®à°¿à°°à±à°šà°¿']
        }
        
        # Marathi
        self.products['mr'] = {
            'grains': ['à¤¤à¤¾à¤‚à¤¦à¥‚à¤³', 'à¤—à¤¹à¥‚', 'à¤œà¤µ', 'à¤®à¤•à¤¾', 'à¤¬à¤¾à¤œà¤°à¥€', 'à¤œà¥à¤µà¤¾à¤°à¥€'],
            'vegetables': ['à¤Ÿà¥‹à¤®à¥‡à¤Ÿà¥‹', 'à¤•à¤¾à¤‚à¤¦à¤¾', 'à¤¬à¤Ÿà¤¾à¤Ÿà¤¾', 'à¤µà¤¾à¤‚à¤—à¥€', 'à¤­à¥‡à¤‚à¤¡à¥€', 'à¤ªà¤¾à¤²à¤•', 'à¤•à¥‹à¤¬à¥€', 'à¤«à¥à¤²à¤•à¥‹à¤¬à¥€', 'à¤µà¤¾à¤Ÿà¤¾à¤£à¥‡', 'à¤˜à¥‡à¤µà¤¡à¤¾'],
            'fruits': ['à¤†à¤‚à¤¬à¤¾', 'à¤•à¥‡à¤³à¥€', 'à¤¸à¤«à¤°à¤šà¤‚à¤¦', 'à¤¸à¤‚à¤¤à¥à¤°à¥€', 'à¤¦à¥à¤°à¤¾à¤•à¥à¤·', 'à¤ªà¥‡à¤°à¥‚', 'à¤ªà¤ªà¤ˆ', 'à¤¡à¤¾à¤³à¤¿à¤‚à¤¬'],
            'pulses': ['à¤®à¥‚à¤—', 'à¤®à¤¸à¥‚à¤°', 'à¤¹à¤°à¤­à¤°à¤¾', 'à¤¤à¥‚à¤°', 'à¤‰à¤¡à¥€à¤¦', 'à¤°à¤¾à¤œà¤®à¤¾'],
            'spices': ['à¤¹à¤³à¤¦', 'à¤§à¤¨à¥‡', 'à¤œà¤¿à¤°à¥‡', 'à¤²à¤¾à¤² à¤®à¤¿à¤°à¤šà¥€', 'à¤µà¥‡à¤²à¤šà¥€', 'à¤•à¤¾à¤³à¥€ à¤®à¤¿à¤°à¥€']
        }
        
        # Tamil  
        self.products['ta'] = {
            'grains': ['à®…à®°à®¿à®šà®¿', 'à®•à¯‹à®¤à¯à®®à¯ˆ', 'à®ªà®¾à®°à¯à®²à®¿', 'à®šà¯‹à®³à®®à¯', 'à®•à®®à¯à®ªà¯', 'à®šà¯‹à®³à®®à¯'],
            'vegetables': ['à®¤à®•à¯à®•à®¾à®³à®¿', 'à®µà¯†à®™à¯à®•à®¾à®¯à®®à¯', 'à®‰à®°à¯à®³à¯ˆà®•à¯à®•à®¿à®´à®™à¯à®•à¯', 'à®•à®¤à¯à®¤à®°à®¿à®•à¯à®•à®¾à®¯à¯', 'à®µà¯†à®£à¯à®Ÿà¯ˆà®•à¯à®•à®¾à®¯à¯', 'à®•à¯€à®°à¯ˆ', 'à®®à¯à®Ÿà¯à®Ÿà¯ˆà®•à¯‹à®¸à¯', 'à®•à®¾à®²à®¿à®ƒà®ªà¯à®³à®µà®°à¯', 'à®ªà®Ÿà¯à®Ÿà®¾à®£à®¿', 'à®ªà¯€à®©à¯à®¸à¯'],
            'fruits': ['à®®à®¾à®®à¯à®ªà®´à®®à¯', 'à®µà®¾à®´à¯ˆà®ªà¯à®ªà®´à®®à¯', 'à®†à®ªà¯à®ªà®¿à®³à¯', 'à®†à®°à®žà¯à®šà¯', 'à®¤à®¿à®°à®¾à®Ÿà¯à®šà¯ˆ', 'à®•à¯Šà®¯à¯à®¯à®¾', 'à®ªà®ªà¯à®ªà®¾à®³à®¿', 'à®®à®¾à®¤à¯à®³à¯ˆ'],
            'pulses': ['à®ªà®šà®²à¯ˆ', 'à®®à®šà¯‚à®°à¯', 'à®•à®Ÿà®²à¯ˆ', 'à®¤à¯‚à®°à¯', 'à®‰à®³à¯à®¨à¯à®¤à¯', 'à®°à®¾à®œà¯à®®à®¾'],
            'spices': ['à®®à®žà¯à®šà®³à¯', 'à®•à¯Šà®¤à¯à®¤à®®à®²à¯à®²à®¿', 'à®šà¯€à®°à®•à®®à¯', 'à®šà®¿à®µà®ªà¯à®ªà¯ à®®à®¿à®³à®•à®¾à®¯à¯', 'à®à®²à®•à¯à®•à®¾à®¯à¯', 'à®•à®°à¯à®ªà¯à®ªà¯ à®®à®¿à®³à®•à¯']
        }
        
    def add_more_language_units_actions(self):
        """Add units and actions for more languages"""
        # Telugu
        self.units['te'] = ['à°•à°¿à°²à±‹', 'à°—à±à°°à°¾à°®à±à°²à±', 'à°Ÿà°¨à±à°¨à±à°²à±', 'à°•à±à°µà°¿à°‚à°Ÿà°²à±à°¸à±', 'à°¸à°‚à°šà±à°²à±', 'à°ªà±†à°Ÿà±à°Ÿà±†à°²à±', 'à°®à±à°•à±à°•à°²à±']
        self.actions['te'] = {
            'check': ['à°¤à°¨à°¿à°–à±€ à°šà±‡à°¯à°‚à°¡à°¿', 'à°šà±‚à°ªà°¿à°‚à°šà±', 'à°šà±†à°ªà±à°ªà°‚à°¡à°¿', 'à°Žà°‚à°¤ à°‰à°‚à°¦à°¿', 'à°¸à±à°Ÿà°¾à°•à± à°Žà°‚à°¤'],
            'update': ['à°…à°ªà±â€Œà°¡à±‡à°Ÿà± à°šà±‡à°¯à°‚à°¡à°¿', 'à°¸à±†à°Ÿà± à°šà±‡à°¯à°‚à°¡à°¿', 'à°®à°¾à°°à±à°šà°‚à°¡à°¿', 'à°¸à°µà°°à°¿à°‚à°šà°‚à°¡à°¿'],
            'increase': ['à°œà±‹à°¡à°¿à°‚à°šà±', 'à°ªà±†à°‚à°šà±', 'à°®à°°à°¿à°‚à°¤', 'à°ªà±à°²à°¸à±', 'à°…à°¦à°¨à°ªà±'],
            'decrease': ['à°¤à°—à±à°—à°¿à°‚à°šà±', 'à°¤à±€à°¸à°¿à°µà±‡à°¯à±', 'à°¤à°•à±à°•à±à°µ', 'à°®à±ˆà°¨à°¸à±'],
            'remove': ['à°¤à±€à°¸à°¿à°µà±‡à°¯à±', 'à°¤à±Šà°²à°—à°¿à°‚à°šà±', 'à°•à±à°²à°¿à°¯à°°à± à°šà±‡à°¯à±'],
            'add_new': ['à°•à±Šà°¤à±à°¤à°¦à°¿ à°œà±‹à°¡à°¿à°‚à°šà±', 'à°¸à±ƒà°·à±à°Ÿà°¿à°‚à°šà±', 'à°°à°¿à°œà°¿à°¸à±à°Ÿà°°à± à°šà±‡à°¯à±']
        }
        
        # Marathi  
        self.units['mr'] = ['à¤•à¤¿à¤²à¥‹', 'à¤—à¥à¤°à¤¾à¤®', 'à¤Ÿà¤¨', 'à¤•à¥à¤µà¤¿à¤‚à¤Ÿà¤²', 'à¤ªà¥‹à¤¤à¥à¤¯à¤¾', 'à¤ªà¥‡à¤Ÿà¥à¤¯à¤¾', 'à¤¤à¥à¤•à¤¡à¥‡']
        self.actions['mr'] = {
            'check': ['à¤¤à¤ªà¤¾à¤¸à¤¾', 'à¤¦à¤¾à¤–à¤µà¤¾', 'à¤¸à¤¾à¤‚à¤—à¤¾', 'à¤•à¤¿à¤¤à¥€ à¤†à¤¹à¥‡', 'à¤¸à¥à¤Ÿà¥‰à¤• à¤•à¤¿à¤¤à¥€'],
            'update': ['à¤…à¤ªà¤¡à¥‡à¤Ÿ à¤•à¤°à¤¾', 'à¤¸à¥‡à¤Ÿ à¤•à¤°à¤¾', 'à¤¬à¤¦à¤²à¤¾', 'à¤¸à¥à¤§à¤¾à¤°à¤¾'],
            'increase': ['à¤œà¥‹à¤¡à¤¾', 'à¤µà¤¾à¤¢à¤µà¤¾', 'à¤…à¤§à¤¿à¤•', 'à¤ªà¥à¤²à¤¸', 'à¤…à¤¤à¤¿à¤°à¤¿à¤•à¥à¤¤'],
            'decrease': ['à¤•à¤®à¥€ à¤•à¤°à¤¾', 'à¤•à¤¾à¤¢à¤¾', 'à¤•à¤®à¥€', 'à¤®à¤¾à¤¯à¤¨à¤¸'],
            'remove': ['à¤•à¤¾à¤¢à¤¾', 'à¤¹à¤Ÿà¤µà¤¾', 'à¤¸à¤¾à¤« à¤•à¤°à¤¾'],
            'add_new': ['à¤¨à¤µà¥€à¤¨ à¤œà¥‹à¤¡à¤¾', 'à¤¤à¤¯à¤¾à¤° à¤•à¤°à¤¾', 'à¤¨à¥‹à¤‚à¤¦à¤£à¥€ à¤•à¤°à¤¾']
        }
        
        # Tamil
        self.units['ta'] = ['à®•à®¿à®²à¯‹', 'à®•à®¿à®°à®¾à®®à¯', 'à®Ÿà®©à¯', 'à®•à¯à®µà®¿à®£à¯à®Ÿà®²à¯', 'à®šà®¾à®•à¯à®•à¯à®•à®³à¯', 'à®ªà¯†à®Ÿà¯à®Ÿà®¿à®•à®³à¯', 'à®¤à¯à®£à¯à®Ÿà¯à®•à®³à¯']
        self.actions['ta'] = {
            'check': ['à®šà®°à®¿à®ªà®¾à®°à¯à®•à¯à®•à®µà¯à®®à¯', 'à®•à®¾à®Ÿà¯à®Ÿà¯', 'à®šà¯Šà®²à¯à®²à¯à®™à¯à®•à®³à¯', 'à®Žà®µà¯à®µà®³à®µà¯ à®‰à®³à¯à®³à®¤à¯', 'à®¸à¯à®Ÿà®¾à®•à¯ à®Žà®µà¯à®µà®³à®µà¯'],
            'update': ['à®ªà¯à®¤à¯à®ªà¯à®ªà®¿à®•à¯à®•à®µà¯à®®à¯', 'à®…à®®à¯ˆà®•à¯à®•à®µà¯à®®à¯', 'à®®à®¾à®±à¯à®±à®µà¯à®®à¯', 'à®¤à®¿à®°à¯à®¤à¯à®¤à®µà¯à®®à¯'],
            'increase': ['à®šà¯‡à®°à¯à®•à¯à®•à®µà¯à®®à¯', 'à®…à®¤à®¿à®•à®°à®¿à®•à¯à®•à®µà¯à®®à¯', 'à®®à¯‡à®²à¯à®®à¯', 'à®ªà®¿à®³à®¸à¯', 'à®•à¯‚à®Ÿà¯à®¤à®²à¯'],
            'decrease': ['à®•à¯à®±à¯ˆà®•à¯à®•à®µà¯à®®à¯', 'à®Žà®Ÿà¯à®•à¯à®•à®µà¯à®®à¯', 'à®•à¯à®±à¯ˆà®µà¯', 'à®®à¯ˆà®©à®¸à¯'],
            'remove': ['à®…à®•à®±à¯à®±à®µà¯à®®à¯', 'à®¨à¯€à®•à¯à®•à®µà¯à®®à¯', 'à®…à®´à®¿à®•à¯à®•à®µà¯à®®à¯'],
            'add_new': ['à®ªà¯à®¤à®¿à®¯à®¤à¯ à®šà¯‡à®°à¯à®•à¯à®•à®µà¯à®®à¯', 'à®‰à®°à¯à®µà®¾à®•à¯à®•à®µà¯à®®à¯', 'à®ªà®¤à®¿à®µà¯ à®šà¯†à®¯à¯à®¯à®µà¯à®®à¯']
        }
        
    def add_translated_patterns(self):
        """Add conversation patterns for other languages"""
        self.conversation_patterns_hi = {
            'check': [
                "à¤®à¥‡à¤°à¥‡ à¤ªà¤¾à¤¸ {product} à¤•à¤¿à¤¤à¤¨à¤¾ à¤¹à¥ˆ?",
                "à¤®à¥‡à¤°à¤¾ {product} à¤¸à¥à¤Ÿà¥‰à¤• à¤šà¥‡à¤• à¤•à¤°à¥‡à¤‚", 
                "{product} à¤•à¥€ à¤®à¥Œà¤œà¥‚à¤¦à¤¾ à¤‡à¤¨à¥à¤µà¥‡à¤‚à¤Ÿà¤°à¥€ à¤•à¥à¤¯à¤¾ à¤¹à¥ˆ?",
                "à¤®à¥à¤à¥‡ {product} à¤•à¥€ à¤®à¤¾à¤¤à¥à¤°à¤¾ à¤¦à¤¿à¤–à¤¾à¤à¤‚",
                "{product} à¤•à¥‡ à¤¸à¥à¤Ÿà¥‰à¤• à¤²à¥‡à¤µà¤² à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤¬à¤¤à¤¾à¤à¤‚"
            ],
            'update': [
                "{product} à¤•à¥‹ {quantity} {unit} à¤ªà¤° à¤…à¤ªà¤¡à¥‡à¤Ÿ à¤•à¤°à¥‡à¤‚",
                "{product} à¤¸à¥à¤Ÿà¥‰à¤• à¤•à¥‹ {quantity} {unit} à¤¸à¥‡à¤Ÿ à¤•à¤°à¥‡à¤‚", 
                "{product} à¤•à¥€ à¤®à¤¾à¤¤à¥à¤°à¤¾ à¤•à¥‹ {quantity} {unit} à¤¬à¤¦à¤²à¥‡à¤‚",
                "{product} à¤•à¥‹ {quantity} {unit} à¤¬à¤¨à¤¾à¤à¤‚",
                "{product} à¤¸à¥à¤Ÿà¥‰à¤• à¤•à¥‹ {quantity} {unit} à¤¸à¤‚à¤¶à¥‹à¤§à¤¿à¤¤ à¤•à¤°à¥‡à¤‚"
            ],
            'increase': [
                "{product} à¤®à¥‡à¤‚ {quantity} {unit} à¤œà¥‹à¤¡à¤¼à¥‡à¤‚",
                "{product} à¤•à¥‹ {quantity} {unit} à¤¸à¥‡ à¤¬à¤¢à¤¼à¤¾à¤à¤‚",
                "à¤®à¥à¤à¥‡ {quantity} {unit} à¤”à¤° {product} à¤®à¤¿à¤²à¤¾",
                "à¤ªà¥à¤²à¤¸ {quantity} {unit} {product}",
                "{product} à¤•à¤¾ à¤…à¤¤à¤¿à¤°à¤¿à¤•à¥à¤¤ {quantity} {unit}"
            ],
            'decrease': [
                "{product} à¤¸à¥‡ {quantity} {unit} à¤¹à¤Ÿà¤¾à¤à¤‚",
                "{product} à¤•à¥‹ {quantity} {unit} à¤¸à¥‡ à¤•à¤® à¤•à¤°à¥‡à¤‚",
                "{product} à¤•à¤¾ {quantity} {unit} à¤¬à¥‡à¤šà¤¾",
                "à¤®à¤¾à¤‡à¤¨à¤¸ {quantity} {unit} {product}",
                "{product} à¤•à¥‹ {quantity} {unit} à¤¸à¥‡ à¤˜à¤Ÿà¤¾à¤à¤‚"
            ],
            'remove': [
                "à¤¸à¤­à¥€ {product} à¤¹à¤Ÿà¤¾à¤à¤‚",
                "à¤‡à¤¨à¥à¤µà¥‡à¤‚à¤Ÿà¤°à¥€ à¤¸à¥‡ {product} à¤¡à¤¿à¤²à¥€à¤Ÿ à¤•à¤°à¥‡à¤‚",
                "{product} à¤¸à¥à¤Ÿà¥‰à¤• à¤¸à¤¾à¤« à¤•à¤°à¥‡à¤‚",
                "à¤¸à¤­à¥€ {product} à¤¨à¤¿à¤•à¤¾à¤²à¥‡à¤‚",
                "{product} à¤•à¥‹ à¤ªà¥‚à¤°à¥€ à¤¤à¤°à¤¹ à¤¹à¤Ÿà¤¾à¤à¤‚"
            ],
            'add_new': [
                "à¤‡à¤¨à¥à¤µà¥‡à¤‚à¤Ÿà¤°à¥€ à¤®à¥‡à¤‚ à¤¨à¤¯à¤¾ {product} à¤œà¥‹à¤¡à¤¼à¥‡à¤‚",
                "{product} à¤•à¥‹ à¤¨à¤ à¤‰à¤¤à¥à¤ªà¤¾à¤¦ à¤•à¥‡ à¤°à¥‚à¤ª à¤®à¥‡à¤‚ à¤°à¤œà¤¿à¤¸à¥à¤Ÿà¤° à¤•à¤°à¥‡à¤‚",
                "à¤®à¥‡à¤°à¥‡ à¤¸à¥à¤Ÿà¥‰à¤• à¤®à¥‡à¤‚ {product} à¤¶à¤¾à¤®à¤¿à¤² à¤•à¤°à¥‡à¤‚",
                "{product} à¤•à¥‡ à¤²à¤¿à¤ à¤¨à¤ˆ à¤à¤‚à¤Ÿà¥à¤°à¥€ à¤¬à¤¨à¤¾à¤à¤‚",
                "à¤®à¥‡à¤°à¥€ à¤‰à¤¤à¥à¤ªà¤¾à¤¦ à¤¸à¥‚à¤šà¥€ à¤®à¥‡à¤‚ {product} à¤œà¥‹à¤¡à¤¼à¥‡à¤‚"
            ]
        }
        
        self.conversation_patterns_bn = {
            'check': [
                "à¦†à¦®à¦¾à¦° à¦•à¦¾à¦›à§‡ {product} à¦•à¦¤ à¦†à¦›à§‡?",
                "à¦†à¦®à¦¾à¦° {product} à¦¸à§à¦Ÿà¦• à¦šà§‡à¦• à¦•à¦°à§à¦¨",
                "{product} à¦à¦° à¦¬à¦°à§à¦¤à¦®à¦¾à¦¨ à¦‡à¦¨à¦­à§‡à¦¨à§à¦Ÿà¦°à¦¿ à¦•à¦¿?",
                "à¦†à¦®à¦¾à¦•à§‡ {product} à¦à¦° à¦ªà¦°à¦¿à¦®à¦¾à¦£ à¦¦à§‡à¦–à¦¾à¦¨",
                "{product} à¦à¦° à¦¸à§à¦Ÿà¦• à¦²à§‡à¦­à§‡à¦² à¦¸à¦®à§à¦ªà¦°à§à¦•à§‡ à¦¬à¦²à§à¦¨"
            ],
            'update': [
                "{product} à¦•à§‡ {quantity} {unit} à¦ à¦†à¦ªà¦¡à§‡à¦Ÿ à¦•à¦°à§à¦¨",
                "{product} à¦¸à§à¦Ÿà¦• {quantity} {unit} à¦¸à§‡à¦Ÿ à¦•à¦°à§à¦¨",
                "{product} à¦à¦° à¦ªà¦°à¦¿à¦®à¦¾à¦£ {quantity} {unit} à¦ à¦ªà¦°à¦¿à¦¬à¦°à§à¦¤à¦¨ à¦•à¦°à§à¦¨",
                "{product} à¦•à§‡ {quantity} {unit} à¦•à¦°à§à¦¨",
                "{product} à¦¸à§à¦Ÿà¦• {quantity} {unit} à¦ à¦¸à¦‚à¦¶à§‹à¦§à¦¨ à¦•à¦°à§à¦¨"
            ],
            'increase': [
                "{product} à¦ {quantity} {unit} à¦¯à§‹à¦— à¦•à¦°à§à¦¨",
                "{product} à¦•à§‡ {quantity} {unit} à¦¦à¦¿à¦¯à¦¼à§‡ à¦¬à¦¾à¦¡à¦¼à¦¾à¦¨",
                "à¦†à¦®à¦¿ {quantity} {unit} à¦†à¦°à§‹ {product} à¦ªà§‡à¦¯à¦¼à§‡à¦›à¦¿",
                "à¦ªà§à¦²à¦¾à¦¸ {quantity} {unit} {product}",
                "{product} à¦à¦° à¦…à¦¤à¦¿à¦°à¦¿à¦•à§à¦¤ {quantity} {unit}"
            ],
            'decrease': [
                "{product} à¦¥à§‡à¦•à§‡ {quantity} {unit} à¦¸à¦°à¦¾à¦¨",
                "{product} à¦•à§‡ {quantity} {unit} à¦¦à¦¿à¦¯à¦¼à§‡ à¦•à¦®à¦¾à¦¨",
                "{product} à¦à¦° {quantity} {unit} à¦¬à¦¿à¦•à§à¦°à¦¿ à¦•à¦°à§‡à¦›à¦¿",
                "à¦®à¦¾à¦‡à¦¨à¦¾à¦¸ {quantity} {unit} {product}",
                "{product} à¦•à§‡ {quantity} {unit} à¦¦à¦¿à¦¯à¦¼à§‡ à¦¹à§à¦°à¦¾à¦¸ à¦•à¦°à§à¦¨"
            ],
            'remove': [
                "à¦¸à¦¬ {product} à¦¸à¦°à¦¾à¦¨",
                "à¦‡à¦¨à¦­à§‡à¦¨à§à¦Ÿà¦°à¦¿ à¦¥à§‡à¦•à§‡ {product} à¦®à§à¦›à§à¦¨",
                "{product} à¦¸à§à¦Ÿà¦• à¦ªà¦°à¦¿à¦·à§à¦•à¦¾à¦° à¦•à¦°à§à¦¨",
                "à¦¸à¦¬ {product} à¦¬à§‡à¦° à¦•à¦°à§à¦¨",
                "{product} à¦¸à¦®à§à¦ªà§‚à¦°à§à¦£à¦­à¦¾à¦¬à§‡ à¦¸à¦°à¦¾à¦¨"
            ],
            'add_new': [
                "à¦‡à¦¨à¦­à§‡à¦¨à§à¦Ÿà¦°à¦¿à¦¤à§‡ à¦¨à¦¤à§à¦¨ {product} à¦¯à§‹à¦— à¦•à¦°à§à¦¨",
                "{product} à¦•à§‡ à¦¨à¦¤à§à¦¨ à¦ªà¦£à§à¦¯ à¦¹à¦¿à¦¸à¦¾à¦¬à§‡ à¦°à§‡à¦œà¦¿à¦¸à§à¦Ÿà¦¾à¦° à¦•à¦°à§à¦¨",
                "à¦†à¦®à¦¾à¦° à¦¸à§à¦Ÿà¦•à§‡ {product} à¦…à¦¨à§à¦¤à¦°à§à¦­à§à¦•à§à¦¤ à¦•à¦°à§à¦¨",
                "{product} à¦à¦° à¦œà¦¨à§à¦¯ à¦¨à¦¤à§à¦¨ à¦à¦¨à§à¦Ÿà§à¦°à¦¿ à¦¤à§ˆà¦°à¦¿ à¦•à¦°à§à¦¨",
                "à¦†à¦®à¦¾à¦° à¦ªà¦£à§à¦¯ à¦¤à¦¾à¦²à¦¿à¦•à¦¾à¦¯à¦¼ {product} à¦¯à§‹à¦— à¦•à¦°à§à¦¨"
            ]
        }
        
    def generate_quantities(self) -> List[Tuple[int, str]]:
        """Generate realistic quantity and unit combinations"""
        quantities = []
        
        # Small quantities (1-50 kg)
        for i in range(1, 51):
            quantities.append((i, 'kg'))
            
        # Medium quantities (50-200 kg) 
        for i in range(50, 201, 5):
            quantities.append((i, 'kg'))
            
        # Large quantities (200-1000 kg)
        for i in range(200, 1001, 25):
            quantities.append((i, 'kg'))
            
        # Quintal quantities (1-10 quintals = 100-1000 kg)
        for i in range(1, 11):
            quantities.append((i, 'quintals'))
            
        # Bag quantities (common for grains)
        for i in range(1, 21):
            quantities.append((i, 'bags'))
            
        # Box quantities (for fruits/vegetables)
        for i in range(1, 51):
            quantities.append((i, 'boxes'))
            
        return quantities
        
    def generate_conversation_sample(self, language: str, action: str, product: str, 
                                   quantity: int = None, unit: str = None) -> Dict[str, Any]:
        """Generate a single conversation sample"""
        
        # Get language-specific data
        products = self.products.get(language, self.products['en'])
        actions = self.actions.get(language, self.actions['en'])
        units_lang = self.units.get(language, self.units['en'])
        
        # Get conversation patterns
        if language == 'hi':
            patterns = self.conversation_patterns_hi
        elif language == 'bn':
            patterns = self.conversation_patterns_bn
        else:
            patterns = self.conversation_patterns
            
        # Select random product from appropriate category
        all_products = []
        for category in products.values():
            all_products.extend(category)
        
        if product == 'random':
            product = random.choice(all_products)
            
        # Generate user input based on action
        action_words = actions.get(action, actions['check'])
        action_word = random.choice(action_words)
        
        if action in ['update', 'increase', 'decrease'] and quantity and unit:
            # Convert unit to target language
            unit_idx = min(len(units_lang) - 1, random.randint(0, len(units_lang) - 1))
            unit_lang = units_lang[unit_idx]
            
            if language in patterns and action in patterns[language]:
                pattern = random.choice(patterns[language][action])
                user_input = pattern.format(product=product, quantity=quantity, unit=unit_lang)
            else:
                pattern = random.choice(patterns[action])
                user_input = pattern.format(product=product, quantity=quantity, unit=unit_lang)
        else:
            if language in patterns and action in patterns[language]:
                pattern = random.choice(patterns[language][action])
                user_input = pattern.format(product=product)
            else:
                pattern = random.choice(patterns[action])  
                user_input = pattern.format(product=product)
        
        # Generate expected response/intent
        intent = {
            'action': action,
            'product': product,
            'language': language
        }
        
        if quantity and unit:
            intent['quantity'] = quantity
            intent['unit'] = unit
            
        # Generate appropriate AI response
        response = self.generate_ai_response(action, product, quantity, unit, language)
        
        return {
            'input': user_input,
            'intent': intent,
            'response': response,
            'language': language,
            'metadata': {
                'timestamp': datetime.now().isoformat(),
                'action_type': action,
                'product_category': self.get_product_category(product, language)
            }
        }
        
    def get_product_category(self, product: str, language: str) -> str:
        """Get the category of a product"""
        products = self.products.get(language, self.products['en'])
        for category, items in products.items():
            if product in items:
                return category
        return 'unknown'
        
    def generate_ai_response(self, action: str, product: str, quantity: int = None, 
                           unit: str = None, language: str = 'en') -> str:
        """Generate appropriate AI response for the action"""
        
        responses = {
            'en': {
                'check': f"Your current {product} inventory is showing. Let me fetch the details for you.",
                'update': f"I've updated your {product} inventory to {quantity} {unit}." if quantity else f"I've updated your {product} inventory.",
                'increase': f"I've added {quantity} {unit} of {product} to your inventory." if quantity else f"I've increased your {product} stock.",
                'decrease': f"I've removed {quantity} {unit} of {product} from your inventory." if quantity else f"I've decreased your {product} stock.",
                'remove': f"I've removed all {product} from your inventory.",
                'add_new': f"I've added {product} as a new item in your inventory."
            },
            'hi': {
                'check': f"à¤†à¤ªà¤•à¥€ à¤µà¤°à¥à¤¤à¤®à¤¾à¤¨ {product} à¤‡à¤¨à¥à¤µà¥‡à¤‚à¤Ÿà¤°à¥€ à¤¦à¤¿à¤–à¤¾à¤ˆ à¤œà¤¾ à¤°à¤¹à¥€ à¤¹à¥ˆà¥¤ à¤®à¥ˆà¤‚ à¤†à¤ªà¤•à¥‡ à¤²à¤¿à¤ à¤µà¤¿à¤µà¤°à¤£ à¤²à¤¾à¤¤à¤¾ à¤¹à¥‚à¤‚à¥¤",
                'update': f"à¤®à¥ˆà¤‚à¤¨à¥‡ à¤†à¤ªà¤•à¥€ {product} à¤‡à¤¨à¥à¤µà¥‡à¤‚à¤Ÿà¤°à¥€ à¤•à¥‹ {quantity} {unit} à¤ªà¤° à¤…à¤ªà¤¡à¥‡à¤Ÿ à¤•à¤° à¤¦à¤¿à¤¯à¤¾ à¤¹à¥ˆà¥¤" if quantity else f"à¤®à¥ˆà¤‚à¤¨à¥‡ à¤†à¤ªà¤•à¥€ {product} à¤‡à¤¨à¥à¤µà¥‡à¤‚à¤Ÿà¤°à¥€ à¤…à¤ªà¤¡à¥‡à¤Ÿ à¤•à¤° à¤¦à¥€ à¤¹à¥ˆà¥¤",
                'increase': f"à¤®à¥ˆà¤‚à¤¨à¥‡ à¤†à¤ªà¤•à¥€ à¤‡à¤¨à¥à¤µà¥‡à¤‚à¤Ÿà¤°à¥€ à¤®à¥‡à¤‚ {quantity} {unit} {product} à¤œà¥‹à¤¡à¤¼ à¤¦à¤¿à¤¯à¤¾ à¤¹à¥ˆà¥¤" if quantity else f"à¤®à¥ˆà¤‚à¤¨à¥‡ à¤†à¤ªà¤•à¤¾ {product} à¤¸à¥à¤Ÿà¥‰à¤• à¤¬à¤¢à¤¼à¤¾ à¤¦à¤¿à¤¯à¤¾ à¤¹à¥ˆà¥¤",
                'decrease': f"à¤®à¥ˆà¤‚à¤¨à¥‡ à¤†à¤ªà¤•à¥€ à¤‡à¤¨à¥à¤µà¥‡à¤‚à¤Ÿà¤°à¥€ à¤¸à¥‡ {quantity} {unit} {product} à¤¹à¤Ÿà¤¾ à¤¦à¤¿à¤¯à¤¾ à¤¹à¥ˆà¥¤" if quantity else f"à¤®à¥ˆà¤‚à¤¨à¥‡ à¤†à¤ªà¤•à¤¾ {product} à¤¸à¥à¤Ÿà¥‰à¤• à¤•à¤® à¤•à¤° à¤¦à¤¿à¤¯à¤¾ à¤¹à¥ˆà¥¤",
                'remove': f"à¤®à¥ˆà¤‚à¤¨à¥‡ à¤†à¤ªà¤•à¥€ à¤‡à¤¨à¥à¤µà¥‡à¤‚à¤Ÿà¤°à¥€ à¤¸à¥‡ à¤¸à¤­à¥€ {product} à¤¹à¤Ÿà¤¾ à¤¦à¤¿à¤¯à¤¾ à¤¹à¥ˆà¥¤",
                'add_new': f"à¤®à¥ˆà¤‚à¤¨à¥‡ {product} à¤•à¥‹ à¤†à¤ªà¤•à¥€ à¤‡à¤¨à¥à¤µà¥‡à¤‚à¤Ÿà¤°à¥€ à¤®à¥‡à¤‚ à¤à¤• à¤¨à¤ˆ à¤µà¤¸à¥à¤¤à¥ à¤•à¥‡ à¤°à¥‚à¤ª à¤®à¥‡à¤‚ à¤œà¥‹à¤¡à¤¼ à¤¦à¤¿à¤¯à¤¾ à¤¹à¥ˆà¥¤"
            },
            'bn': {
                'check': f"à¦†à¦ªà¦¨à¦¾à¦° à¦¬à¦°à§à¦¤à¦®à¦¾à¦¨ {product} à¦‡à¦¨à¦­à§‡à¦¨à§à¦Ÿà¦°à¦¿ à¦¦à§‡à¦–à¦¾à¦¨à§‹ à¦¹à¦šà§à¦›à§‡à¥¤ à¦†à¦®à¦¿ à¦†à¦ªà¦¨à¦¾à¦° à¦œà¦¨à§à¦¯ à¦¬à¦¿à¦¸à§à¦¤à¦¾à¦°à¦¿à¦¤ à¦†à¦¨à¦›à¦¿à¥¤",
                'update': f"à¦†à¦®à¦¿ à¦†à¦ªà¦¨à¦¾à¦° {product} à¦‡à¦¨à¦­à§‡à¦¨à§à¦Ÿà¦°à¦¿ {quantity} {unit} à¦ à¦†à¦ªà¦¡à§‡à¦Ÿ à¦•à¦°à§‡à¦›à¦¿à¥¤" if quantity else f"à¦†à¦®à¦¿ à¦†à¦ªà¦¨à¦¾à¦° {product} à¦‡à¦¨à¦­à§‡à¦¨à§à¦Ÿà¦°à¦¿ à¦†à¦ªà¦¡à§‡à¦Ÿ à¦•à¦°à§‡à¦›à¦¿à¥¤",
                'increase': f"à¦†à¦®à¦¿ à¦†à¦ªà¦¨à¦¾à¦° à¦‡à¦¨à¦­à§‡à¦¨à§à¦Ÿà¦°à¦¿à¦¤à§‡ {quantity} {unit} {product} à¦¯à§‹à¦— à¦•à¦°à§‡à¦›à¦¿à¥¤" if quantity else f"à¦†à¦®à¦¿ à¦†à¦ªà¦¨à¦¾à¦° {product} à¦¸à§à¦Ÿà¦• à¦¬à¦¾à¦¡à¦¼à¦¿à¦¯à¦¼à§‡à¦›à¦¿à¥¤",
                'decrease': f"à¦†à¦®à¦¿ à¦†à¦ªà¦¨à¦¾à¦° à¦‡à¦¨à¦­à§‡à¦¨à§à¦Ÿà¦°à¦¿ à¦¥à§‡à¦•à§‡ {quantity} {unit} {product} à¦¸à¦°à¦¿à¦¯à¦¼à§‡à¦›à¦¿à¥¤" if quantity else f"à¦†à¦®à¦¿ à¦†à¦ªà¦¨à¦¾à¦° {product} à¦¸à§à¦Ÿà¦• à¦•à¦®à¦¿à¦¯à¦¼à§‡à¦›à¦¿à¥¤",
                'remove': f"à¦†à¦®à¦¿ à¦†à¦ªà¦¨à¦¾à¦° à¦‡à¦¨à¦­à§‡à¦¨à§à¦Ÿà¦°à¦¿ à¦¥à§‡à¦•à§‡ à¦¸à¦¬ {product} à¦¸à¦°à¦¿à¦¯à¦¼à§‡ à¦¦à¦¿à¦¯à¦¼à§‡à¦›à¦¿à¥¤",
                'add_new': f"à¦†à¦®à¦¿ {product} à¦•à§‡ à¦†à¦ªà¦¨à¦¾à¦° à¦‡à¦¨à¦­à§‡à¦¨à§à¦Ÿà¦°à¦¿à¦¤à§‡ à¦à¦•à¦Ÿà¦¿ à¦¨à¦¤à§à¦¨ à¦†à¦‡à¦Ÿà§‡à¦® à¦¹à¦¿à¦¸à¦¾à¦¬à§‡ à¦¯à§‹à¦— à¦•à¦°à§‡à¦›à¦¿à¥¤"
            }
        }
        
        lang_responses = responses.get(language, responses['en'])
        return lang_responses.get(action, "I've processed your request.")
        
    def generate_dataset_chunk(self, chunk_size: int = 1000, chunk_id: int = 1) -> List[Dict[str, Any]]:
        """Generate a chunk of training data"""
        dataset = []
        actions = ['check', 'update', 'increase', 'decrease', 'remove', 'add_new']
        quantities = self.generate_quantities()
        
        # Ensure we cover all languages and actions
        samples_per_lang_action = chunk_size // (len(self.languages) * len(actions))
        
        for lang_code in self.languages.keys():
            # Only generate for languages we have data for
            if lang_code not in self.products:
                continue
                
            for action in actions:
                for i in range(samples_per_lang_action):
                    # Randomly select product
                    products = self.products[lang_code]
                    all_products = []
                    for category in products.values():
                        all_products.extend(category)
                    product = random.choice(all_products)
                    
                    # For actions that need quantity, add it
                    quantity = None
                    unit = None
                    if action in ['update', 'increase', 'decrease']:
                        quantity, unit = random.choice(quantities)
                        
                    sample = self.generate_conversation_sample(
                        language=lang_code,
                        action=action, 
                        product=product,
                        quantity=quantity,
                        unit=unit
                    )
                    
                    dataset.append(sample)
                    
        # Fill remaining slots with random samples
        while len(dataset) < chunk_size:
            lang_code = random.choice(list(self.products.keys()))
            action = random.choice(actions)
            
            products = self.products[lang_code]
            all_products = []
            for category in products.values():
                all_products.extend(category)
            product = random.choice(all_products)
            
            quantity = None
            unit = None
            if action in ['update', 'increase', 'decrease']:
                quantity, unit = random.choice(quantities)
                
            sample = self.generate_conversation_sample(
                language=lang_code,
                action=action,
                product=product, 
                quantity=quantity,
                unit=unit
            )
            
            dataset.append(sample)
            
        return dataset
        
    def save_chunk_to_jsonl(self, dataset: List[Dict[str, Any]], chunk_id, output_dir: str = 'training_data'):
        """Save dataset chunk to JSONL file"""
        os.makedirs(output_dir, exist_ok=True)
        
        # Handle both int and string chunk_id
        if isinstance(chunk_id, int):
            filename = f"{output_dir}/farmer_inventory_training_chunk_{chunk_id:03d}.jsonl"
        else:
            filename = f"{output_dir}/farmer_inventory_training_chunk_{chunk_id}.jsonl"
        
        with open(filename, 'w', encoding='utf-8') as f:
            for sample in dataset:
                f.write(json.dumps(sample, ensure_ascii=False) + '\n')
                
        print(f"Saved chunk {chunk_id} with {len(dataset)} samples to {filename}")
        
    def generate_complete_dataset(self, total_samples: int = 50000, chunk_size: int = 5000, 
                                output_dir: str = 'training_data'):
        """Generate complete dataset in chunks"""
        print(f"Generating {total_samples} training samples in chunks of {chunk_size}")
        print(f"Supporting {len(self.languages)} languages: {list(self.languages.values())}")
        
        num_chunks = (total_samples + chunk_size - 1) // chunk_size
        
        for chunk_id in range(1, num_chunks + 1):
            current_chunk_size = min(chunk_size, total_samples - (chunk_id - 1) * chunk_size)
            
            print(f"\nGenerating chunk {chunk_id}/{num_chunks} ({current_chunk_size} samples)...")
            dataset_chunk = self.generate_dataset_chunk(current_chunk_size, chunk_id)
            
            self.save_chunk_to_jsonl(dataset_chunk, chunk_id, output_dir)
            
        print(f"\nâœ… Dataset generation complete!")
        print(f"Generated {total_samples} samples across {num_chunks} chunks")
        print(f"Files saved in '{output_dir}' directory")
        
        # Generate summary statistics
        self.generate_summary_stats(output_dir, num_chunks)
        
    def generate_summary_stats(self, output_dir: str, num_chunks: int):
        """Generate summary statistics for the dataset"""
        stats = {
            'total_chunks': num_chunks,
            'languages_supported': len(self.languages),
            'languages': self.languages,
            'actions_covered': list(self.actions['en'].keys()),
            'sample_distribution': {},
            'generation_timestamp': datetime.now().isoformat()
        }
        
        # Count samples by language and action (from first chunk as sample)
        if num_chunks > 0:
            first_chunk_file = f"{output_dir}/farmer_inventory_training_chunk_001.jsonl"
            if os.path.exists(first_chunk_file):
                lang_counts = {}
                action_counts = {}
                
                with open(first_chunk_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        sample = json.loads(line)
                        lang = sample['language']
                        action = sample['intent']['action']
                        
                        lang_counts[lang] = lang_counts.get(lang, 0) + 1
                        action_counts[action] = action_counts.get(action, 0) + 1
                        
                stats['sample_distribution']['by_language'] = lang_counts
                stats['sample_distribution']['by_action'] = action_counts
        
        with open(f"{output_dir}/dataset_summary.json", 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
            
        print(f"\nðŸ“Š Summary statistics saved to {output_dir}/dataset_summary.json")


def main():
    """Main function to generate the dataset"""
    generator = FarmerInventoryDatasetGenerator()
    
    # Generate production-ready dataset with 100,000 samples in chunks of 5,000
    # This creates a comprehensive dataset suitable for training robust AI models
    generator.generate_complete_dataset(
        total_samples=100000,
        chunk_size=5000,
        output_dir='training_data'
    )


if __name__ == "__main__":
    main()